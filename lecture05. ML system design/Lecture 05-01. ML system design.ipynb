{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "# Лекция 05. Проектирование системы ML\n",
    "## Метрики ошибок для искаженных классов\n",
    "**Что такое искаженные классы?**\n",
    "Искаженные классы в основном относятся к набору данных, в котором число обучающих примеров, принадлежащих одному классу, превышает число обучающих примеров, относящихся к другому классу.\n",
    "\n",
    "Рассмотрим бинарную классификацию, где раковый пациент должен быть обнаружен на основе некоторых признаков. И говорят, что только у 1 из представленных в данных пациентов обнаружен рак. В условиях, когда наличие рака обозначено 1, а его отсутствие обозначено 0, если система наивно дает прогноз как у всех пациентов 0, все равно точность прогноза будет составлять 99%."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# naive prediction ignoring features\n",
    "def predict_cancer(x):\n",
    "    return 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Поэтому можно с уверенностью сказать, что метрика точности или среднеквадратичная ошибка для перекошенных классов, не является надлежащим показателем эффективности модели. Следовательно, существует необходимость в другой метрике ошибок для искаженных классов."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Точность/Recall (полнота).\n",
    "Примечание: $y = 1$ это более редкий класс среди двух.\n",
    "\n",
    "В бинарной классификации может возникнуть один из следующих четырех сценариев:\n",
    "\n",
    "* True Positive (TP): модель предсказывает 1, и фактический класс равен 1\n",
    "* True Negative (TN): модель предсказывает 0, и фактический класс равен 0\n",
    "* False Positive (FP): модель предсказывает 1, но фактический класс равен 0\n",
    "* False Negative (FN): модель предсказывает 0, но фактический класс равен 1\n",
    "\n",
    "![](../../img/lec05_f1.png)\n",
    "\n",
    "Тогда точность и полноту можно определить следующим образом:\n",
    "\n",
    "* $точность = \\frac{TP}{(TP + FP)}$\n",
    "* $полнота = \\frac{TP}{(TP + FN)}$\n",
    "\n",
    "Напомним, что все действительные значения определены, как $y = 1$, !!Какие из них правильно предсказала модель.(which ones did the model predict correctly.!)\n",
    "\n",
    "Теперь, если мы оценим сценарий, в котором классификатор предсказывает все 0, то полнота модели будет равена 0, что указывает на недееспособность системы.\n",
    "\n",
    "**В случае искажения классов классификаторы не могут обмануть метрики оценки полноты и точности. Кроме того, важно отметить, что метрики точности и полноты работают лучше, если $y=1$, обозначает наличие более редкого класса.**\n",
    "\n",
    "Изменяя пороговое значение для достоверности классификатора, можно регулировать точность и полноту для модели.\n",
    "\n",
    "Например, в логистической регрессии порог обычно равен 0,5. Если его увеличить, то можно быть уверенным, что из всех сделанных предсказаний больше будет правильных, а значит, и высокоточных. Но есть также более высокие шансы пропустить положительные случаи, следовательно, более низкая полнота.\n",
    "\n",
    "Точно так же, если уменьшить порог, то вероятность ложных срабатываний увеличивается, следовательно, низкая точность. Кроме того, существует меньшая вероятность пропуска фактических случаев, следовательно, возрастает метрика полноты.\n",
    "\n",
    "Кривая компромисса между точностью и полнотой может выглядеть следующим образом,\n",
    "\n",
    "![](../../img/lec05_threshold.gif)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### $F_1$ оценка\n",
    "Учитывая две пары точность и полноту, как выбрать лучшую пару? Одним из вариантов было бы выбрать ту, которая выше среднего. Это не идеальное решение, поскольку пара ($precision=0.02$ и $recall = 1$) имеет лучшее среднее значение, чем пара ($precision=0.5$ и $recall=0.4$).\n",
    "\n",
    "Введем $F оценку$ или $F_1 оценку$, которая является гармоническим средним значением точности и полноты, определяемая как\n",
    "\n",
    " $F_1 = \\frac{2 P*R}{P+R}$\n",
    " \n",
    "  Вышеприведенная формула имеет преимущество перед средним методом, потому что, если точность или полнота невелики, произведение числителя $P∗R$ будет оцениваться в $F_1 - оценке$ низко и, следовательно, приведет к выбору лучшей пары точности и отзыва. Так,\n",
    " * если $P=0$ или $R=0$, то $F_1 = 0$\n",
    " * если $P=1$ и $R=1$, то $F_1 = 1$\n",
    " \n",
    " **Один из разумных способов автоматического выбора порога для классификатора-попробовать их диапазон в наборе перекрестной проверки и выбрать тот, который дает самый высокий балл F.**\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Чувствительность/Специфичность\n",
    "Помимо точности и полноты, чувствительность и специфичность являются одними из наиболее часто используемых показателей ошибок в классификации.\n",
    "\n",
    "* Чувствительность или истинно положительная пропорция (TPR) - это другое название для отзывчивости, а также этот показатель называют попаданием \n",
    "$TPR=\\frac{TP}{TP+FN}$\n",
    "* Специфичность (SPC) или истинно отрицательная пропорция\n",
    "$SPC=\\frac{TN}{TN+FP}$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Диагностика машинного обучения\n",
    "Тест, который вы можете запустить, чтобы получить представление о том, что не работает в алгоритме обучения, и получить рекомендации о том, как можно улучшить его производительность.\n",
    "\n",
    "Диагностика может занять время на реализацию, но это может быть очень хорошим использованием вашего времени.\n",
    "\n",
    "### Диагностирование смещения vs разброса (дисперсии)\n",
    "Предположим, что наш алгоритм обучения (например, линейная регрессия или случайный лес и т.д.) делает огромные ошибки при прогнозировании данных. Итак, что мы можем сделать, чтобы улучшить наш алгоритм обучения? Мы можем уменьшить эти ошибки, попробовав что-то из ниже приведенного:\n",
    "\n",
    "* Использовать больше обучающих данных\n",
    "* Попробовать уменьшить набор признаков\n",
    "* Подобрать новые признаки\n",
    "* Попробовать использовать полиномиальные признаки\n",
    "* Увеличить или уменьшить параметры регуляризации \n",
    "\n",
    "Но чтобы попробовать все или некоторые из этих вариантов, может понадобиться много времени, чтобы понять, что заставляет наш алгоритм плохо работать.\n",
    "\n",
    "Другими словами, если вы запускаете алгоритм обучения, и он не преуспел, то почти всегда это либо проблема с высоким смещением, либо проблема большого разброса. Это два термина в статистике. Таким образом, нам нужно различать, является ли смещение или разброс проблемой, способствующей плохим прогнозам, оценивая гипотезу, которая была отклонена нашим алгоритмом обучения, чтобы понять, подходит ли она или нет?\n",
    "\n",
    "* Смещение измеряет, насколько далеки в целом прогнозы этих моделей от правильного значения.\n",
    "* Разброс - это то, насколько предсказания для данной точки различаются между различными реализациями модели.\n",
    "* Высокое смещение является недообучением, а высокий разброс - переобучением. В идеале, мы должны найти золотую середину между ними двумя.\n",
    "\n",
    "Ошибка обучения будет иметь тенденцию уменьшаться по мере увеличения степени \"d\" полинома. В то же время ошибка перекрестной проверки(кросс-валидации) будет иметь тенденцию уменьшаться по мере увеличения \"d\" до некоторой точки, а затем она будет увеличиваться по мере увеличения \"d\", образуя выпуклую кривую.\n",
    "Это показано на рисунке ниже:\n",
    "![](../../img/lec05_bias_variance.png)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Типичная кривая обучения для большого разброса**\n",
    "![](../../img/lec05_high_variance.png)\n",
    "\n",
    "**Типичная кривая обучения для большого смещения**\n",
    "![](../../img/lec05_high_bias.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Диагностика скажет вам, что следует попробовать дальше:**\n",
    "\n",
    "Попробуйте, чтобы улучшить модель:\n",
    "* Попробуйте получить больше обучающих примеров - исправляет высокую дисперсию\n",
    "* Попробуйте использовать меньший набор параметров - исправляет высокую дисперсию\n",
    "* Попробуйте больший набор параметров - исправляет большое смещение.\n",
    "* Попробуйте добавить дополнительные параметры - исправляет большое смещение.\n",
    "* Запуск градиентного спуска с большим количеством итераций - исправляет алгоритм оптимизации.\n",
    "* Попробуйте метод Ньютона - исправляет алгоритм оптимизации.\n",
    "* Используйте другое значение λ - иправляет объект оптимизации.\n",
    "* Попробуйте использовать SVM - иправляет объект оптимизации.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
